{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPB8fPkJc+9PL8sVFxhizAv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nepslor/teaching/blob/main/TimeSeriesForecasting/inducing_stationarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📖 Seasonally adjusted data - an example\n",
        "The mortality data [recently published](https://www.nature.com/articles/s41597-021-01019-1) by the [Human Mortality Database](https://www.mortality.org/) can be used to explore seasonality in mortality rates as fatalities / 100000 . Mortality rates are known to be seasonal due to temperatures and other weather-related effects (Healy 2003). In the folloing cells we will use STL decomposition to decompose these time series for different countries.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dbphpVmF97ZW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvw45uOy9xSS"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.seasonal import STL\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "stmf = pd.read_csv(\"https://www.mortality.org/File/GetDocument/Public/STMF/Outputs/stmf.csv\",skiprows=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code just adds a DatetimeIndex to the data, from the year and the week columns"
      ],
      "metadata": {
        "id": "-7QtcNE-rr7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stmf.index = pd.DatetimeIndex(pd.DatetimeIndex(stmf['Year'].apply(lambda x: '{}-01-01'.format(x), 0)) + pd.to_timedelta( stmf['Week'].apply(lambda x: '{}d'.format(x * 7), 0)))\n",
        "stmf.head()"
      ],
      "metadata": {
        "id": "VgWr5ws5A1QN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the data of a given year-week is splitted over multiple lines due to the presence of the sex attribute, we need to define an auxiliary function to get the aggregated value regardless of the sex.\n",
        "\n",
        "We additionally define a function returning the matrix form of the data: a dataframe whose rows corresponds to the year and columns to the day of observations."
      ],
      "metadata": {
        "id": "_JusOfAar2Jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_national_obs(data, cc='ITA'):\n",
        "  \"\"\"\n",
        "  Get death rate for a given country\n",
        "  \"\"\"\n",
        "  data = stmf.loc[stmf['CountryCode'] == cc, ['Week', 'Year', 'RTotal']]\n",
        "  return data.groupby(data.index).sum()['RTotal']\n",
        "\n",
        "def get_matrix_form(y):\n",
        "  \"\"\"\n",
        "  Get death rate for a given country, in matrix format (year, week)\n",
        "  \"\"\"\n",
        "  y = pd.concat([y, pd.Series(y.index.year, name='Year', index=y.index),\n",
        "                 pd.Series(y.index.dayofyear, name='Day', index=y.index)], axis=1)\n",
        "  y = y.loc[(y.Day>7) & (y.Year<2023)]\n",
        "  return y.pivot(index='Year', columns='Day', values='RTotal').T\n",
        "\n"
      ],
      "metadata": {
        "id": "abp8wxzDAyEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "SC7rxghLsuZI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y = get_national_obs(stmf, 'NLD')\n",
        "stl = STL(y, seasonal=53, period=52)\n",
        "res = stl.fit()\n",
        "\n",
        "fig = res.plot()\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n",
        "res.observed.plot(ax=ax[0])\n",
        "(res.trend+res.seasonal).plot(ax=ax[0])\n",
        "(res.resid).plot(ax=ax[1])\n"
      ],
      "metadata": {
        "id": "q9sgLfdgENNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's have a look at the seasonal plot of the time series"
      ],
      "metadata": {
        "id": "-CqUl-4_41cQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_mat = get_matrix_form(get_national_obs(stmf,cc='NLD'))\n",
        "\n",
        "fig, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
        "y_mat.plot(alpha=0.3, ax=ax)\n",
        "plt.legend(fontsize='x-small', ncol=4)\n",
        "ax.set_title('seasonal plot')"
      ],
      "metadata": {
        "id": "u3ZXaat04vcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ❓Write a simple seasonal-trend decomposition\n",
        "A simple seasonal-trend decomposition can be achieved using the following method:\n",
        "1. trend: use a lagged moving average of the original signal\n",
        "2. seasonal: median season of the detrended signal\n",
        "\n",
        "you can use the `get_matrix_form` and `get_national_obs` functions to do this."
      ],
      "metadata": {
        "id": "WcudI8Tv6CBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "lagged_mav = lambda x, k: x.rolling('{}d'.format(k)).mean()\n",
        "\n",
        "def simple_std(stmf):\n",
        "  \"\"\"\n",
        "  A simple function that returns trend and seasonal component. The trend is\n",
        "  obtained using the lagged_mav function, while the seasonal component is the\n",
        "  daily median of the detrended profile.\n",
        "  \"\"\"\n",
        "  trend = 0\n",
        "  season = 0\n",
        "  y_seasonal = pd.Series(np.tile(season.values, y_mat.shape[0])[:len(y)], index=y.index)\n",
        "  return trend, y_seasonal\n",
        "\n",
        "trend, y_seasonal = simple_std(stmf)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(1, 3, figsize=(20, 4))\n",
        "y.plot(ax=ax[0])\n",
        "(y_seasonal+trend).plot(ax=ax[0])\n",
        "(y-y_seasonal-trend).plot(ax=ax[1])\n",
        "(trend + y_seasonal).plot(ax=ax[2])\n",
        "(res.trend + res.seasonal).plot(ax=ax[2])\n",
        "ax[0].set_title('simple STd S+T')\n",
        "ax[1].set_title('simple STd R')\n",
        "ax[2].set_title('simple STd vs STL');"
      ],
      "metadata": {
        "id": "9izS2l3AMhWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forecasting with STL decomposition\n",
        "Given the STL decomposiion\n",
        "$$y_t=S_t+T_t+R_t$$\n",
        "we can assume that the seasonal component is slow changing, and repeats itself almost exactly. This means that we can use the seasonal naive method we've seen in the last lesson to forecast the seasonal component and then use a forecasting model to just predict $T_t+R_t$.\n",
        "$$\n",
        "\\begin{align}\n",
        "\\hat{y}_{T+h}&= \\hat{S}_{T+h} + f(T_T+R_T) \\qquad \\ \\text{forecasting model + seasonal forecast}\\\\\n",
        "\\hat{S}_{T+h}&=\\hat{S}_{T-k} \\qquad\\qquad\\qquad\\qquad \\text{seasonal naive}\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "where $k=m-h+m\\lfloor(h-1) / m\\rfloor$\n",
        "\n",
        "\\\\\n",
        "<div>\n",
        "<img src=\"https://raw.githubusercontent.com/nepslor/teaching/main/TimeSeriesForecasting/figs/Baregg_tunnel.png\" width=\"400\" align=\"right\"/>\n",
        "</div>\n",
        "\n",
        "Tunnel Traffic is a time series describing the number of vehicles traveling through the Baregg Tunnel in Switzerland each day from November 2003 to November 2005.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VsvS-d1YSsbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/nepslor/teaching/main/TimeSeriesForecasting/data/tunnel.csv', parse_dates=True, index_col=0)\n",
        "print(data.head())\n",
        "data.plot()"
      ],
      "metadata": {
        "id": "dLFx2sj_OR5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We start by decomposing the data with the STL and plotting it"
      ],
      "metadata": {
        "id": "hHb0_qIG7lY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stl = STL(data, seasonal=7)\n",
        "res = stl.fit()\n",
        "\n",
        "fig = res.plot()\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 4))\n",
        "res.observed.plot(ax=ax[0])\n",
        "(res.trend+res.seasonal).plot(ax=ax[0])\n",
        "(res.trend+res.resid).plot(ax=ax[1])"
      ],
      "metadata": {
        "id": "x1MGFtGtbxHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple linear forecaster\n",
        "In the following, we have defined a simple linear forecaster for a univariate time series. The forecaster retrieves the embedding matrix $E(e)$:\n",
        "$$E(e) = \\left[\\begin{array}{cccc}x(t-m) &\\cdots &x(t) &\\cdots x(t+f)\\\\\n",
        "x(t-m+1) &\\cdots &x(t+1) &\\cdots x(t+f+1)\\\\\n",
        "\\ldots & \\ldots & \\cdots & \\cdots\\\\\n",
        "x(T-m-f) &\\cdots &x(T-f) &\\cdots x(T) \\end{array}\\right]=[X, Y]$$\n",
        "where $e = m + f$ and $m$ and $f$ are the number of past steps used as features and the number of steps ahead to be forecasted, respectively.\n",
        "\n",
        "The forecaster is then fitted as:\n",
        "$$\\theta = (X_{tr}^T X_{tr})^{-1}X_{tr}^T Y_{tr}$$\n",
        "and predicts through\n",
        "$$\\hat{y} = X_{te}\\theta$$\n",
        "\n",
        "\n",
        "\n",
        "❓ In the following cell we have defined a LinearForecaster class. Try to complete the fit method with the values of x and target, using the get_hankel function."
      ],
      "metadata": {
        "id": "ImUoyGpPGdw2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_hankel(df, embedding=3):\n",
        "  return pd.concat([df.shift(-l) for l in range(embedding)], axis=1).iloc[:-embedding]\n",
        "\n",
        "\n",
        "class LinearForecaster:\n",
        "  \"\"\"\n",
        "  A simple linear forecaster: retrieves the signal's Hankel matrix of\n",
        "  the requested embedding and fits a linear regression on future values.\n",
        "  \"\"\"\n",
        "  def __init__(self, steps_ahead=1, embedding=3):\n",
        "    self.steps_ahead = steps_ahead\n",
        "    self.embedding = embedding\n",
        "    self.theta = None\n",
        "    self.mean = None\n",
        "    self.std = None\n",
        "\n",
        "  def fit(self, y0):\n",
        "    y = y0.copy()\n",
        "    self.mean = np.array(y.mean())\n",
        "    self.std = np.array(y.std())\n",
        "    x = 0\n",
        "    target = 0\n",
        "    self.theta = np.linalg.pinv(x.T@x)@(x.T@target)\n",
        "    return self\n",
        "\n",
        "  def predict(self, df):\n",
        "    x = df.iloc[-self.embedding:].values.reshape(1, -1)/self.std-self.mean\n",
        "    preds = x @ self.theta\n",
        "    return pd.DataFrame(preds.ravel(), index=df.iloc[-self.steps_ahead:].index + pd.to_timedelta('{}d'.format(self.steps_ahead)), columns=['y_hat_lin'])\n",
        "\n"
      ],
      "metadata": {
        "id": "cXD_KFKZfnRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ❓Write a STL decomposition forecaster\n",
        "In the followin, try to complete the fit method of the STLLinearForecaster class"
      ],
      "metadata": {
        "id": "Ld50K1qhLW4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class STLLinearForecaster:\n",
        "  def __init__(self, seasonality=13, linear_embedding=3):\n",
        "    self.seasonality = seasonality\n",
        "    self.linear_embedding = linear_embedding\n",
        "    self.rt_model = LinearForecaster(steps_ahead=seasonality, embedding=linear_embedding)\n",
        "    self.seasonal_component = None\n",
        "\n",
        "  def fit(self, df):\n",
        "    # STL decomposition of the signal\n",
        "\n",
        "    # Linear model fit\n",
        "\n",
        "    return self\n",
        "\n",
        "  def predict(self, df):\n",
        "    s_t = self.seasonal_component.iloc[-self.seasonality:]\n",
        "    rt_t = self.rt_model.predict(df)\n",
        "    return pd.DataFrame(s_t.values + rt_t.values.ravel(), index=df.iloc[-self.seasonality:].index + pd.to_timedelta('{}d'.format(self.seasonality)), columns=['y_hat_stl'])"
      ],
      "metadata": {
        "id": "A44N5jiGGa3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "the following cell computes a 30 folds cross validation of the linear and STL-linar forecasters"
      ],
      "metadata": {
        "id": "xHxl7hCRd9No"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation(*models, steps_ahead=7, embedding=7, do_plot=False):\n",
        "\n",
        "  forecasters = [m(steps_ahead=steps_ahead, embedding=embedding) for m in models]\n",
        "  names = [m.__name__ for m in models]\n",
        "  nmae = lambda x, y: np.mean(np.abs(x - y)) / np.mean(np.abs(y))\n",
        "\n",
        "\n",
        "  scores = {}\n",
        "  for i in range(30):\n",
        "      k = 7 * i + 7 * 30\n",
        "      data_tr, data_te = data.iloc[:k], data.iloc[k:k + steps_ahead]\n",
        "      preds = {n: f.fit(data_tr).predict(data_tr) for n, f in zip(names, forecasters)}\n",
        "      scores[i] = {n: nmae(data_te.values, p.values) for n, p in preds.items()}\n",
        "      if do_plot:\n",
        "        fig, ax = plt.subplots(1, 1)\n",
        "        data_te.plot(ax=ax)\n",
        "        data.iloc[k - 7 * 6:k].plot(ax=ax)\n",
        "        [p.plot(ax=ax) for p in preds.values()]\n",
        "\n",
        "  return pd.DataFrame(scores).mean(axis=1)\n",
        "\n",
        "cross_validation(LinearForecaster, STLLinearForecaster, do_plot=True)"
      ],
      "metadata": {
        "id": "O-Wz1zquin_j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Memory of the process\n",
        "We have just seen that the performances of the STL-linear forecaster are better then the vanilla linear forecaster, if we take the past embedding equal to the step ahad to be forecasted (7 in this case).\n",
        "Since this embedding is a common parameter to both the models, we can wonder what happens if we increase it.\n",
        "\n",
        "❓ Try to systematically increase the embedding and the linear_embedding paraeters invoking `cross_validation` and see if the performance goes as expected.\n",
        "\n"
      ],
      "metadata": {
        "id": "uKrPMiCra8he"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LBCbwGHa2pLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inducing stationarity via lagged MA\n",
        "\n",
        "Why does the performance decreases badly at increasing embeddings for the `STLLinearForecaster`?\n",
        "\n",
        "The only part of the `STLLinearForecaster` model affected by the embedding time is the linear part, which is forecasting the T+R part. If we plot T+R, we can see that there's little hope that the linear model will benefit from an increasing learning horizon. This can better seen plotting its ACF.\n",
        "\n",
        "On the other hand, a good idea to obtain a forecastable stationary signal, would be to use a lagged MA. We can then forecast the detrended signal and just add the last value of the MA to get the final prediction. In the next cell we see the difference in the ACF functions for the signals to be forecasted by the two aforementioned strategies.\n",
        "\n"
      ],
      "metadata": {
        "id": "e5qrv_Gfcec1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "seasonality = 7\n",
        "trend = lagged_mav(data, seasonality)\n",
        "\n",
        "\n",
        "fig, ax = plt.subplots(2, 2 , figsize=(20, 8))\n",
        "\n",
        "# plot Trend and Residuals from STL decomposition, along with its ACF\n",
        "(res.trend+res.resid).plot(ax=ax[0, 0], title='T+R')\n",
        "_ = sm.graphics.tsa.plot_acf(res.trend+res.resid, lags=40, ax=ax[0, 1], title='T+R ACF')\n",
        "\n",
        "# plot the signal detrended with the lagged MAV and its ACF\n",
        "(data-trend).plot(ax=ax[1, 0], title='detrended with lagged MAV')\n",
        "_ = sm.graphics.tsa.plot_acf(data-trend, lags=40, ax=ax[1, 1], title='detrended with lagged MAV ACF')"
      ],
      "metadata": {
        "id": "IEg-vlCMxAPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code defines a linear forecaster that applies a lagged MA detrend before fitting the model\n"
      ],
      "metadata": {
        "id": "mrpiNPMR3Dey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearDetrendedForecaster:\n",
        "  def __init__(self, steps_ahead=13, embedding=3):\n",
        "    self.steps_ahead = steps_ahead\n",
        "    self.embedding = embedding\n",
        "    self.rt_model = LinearForecaster(steps_ahead=steps_ahead, embedding=embedding)\n",
        "\n",
        "  def fit(self, df):\n",
        "    # signal detrending\n",
        "    trend = lagged_mav(df, self.steps_ahead)\n",
        "    self.rt_model.fit(df-trend)\n",
        "    return self\n",
        "\n",
        "  def predict(self, df):\n",
        "    trend = lagged_mav(df, self.steps_ahead)\n",
        "    y_hat = self.rt_model.predict(df-trend) + trend.iloc[-1].values\n",
        "    y_hat.name = 'lin_detrended'\n",
        "    return y_hat"
      ],
      "metadata": {
        "id": "grZsOrI1Qn7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.concat({i*7:cross_validation(LinearForecaster, STLLinearForecaster, LinearDetrendedForecaster, embedding=7*i) for i in range(1, 5)}, axis=1)\n",
        "results.T.plot()\n",
        "plt.ylabel('nMAE');"
      ],
      "metadata": {
        "id": "5-_36mpEQmgs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forecasting by whitening\n",
        "Another powerful method to forecast a time series is to try to make it uncorrelated and iid by applying a composition of (deterministic) invertible transformations. For example, in this case, we can try to apply the following transformations:\n",
        "\n",
        "$$x^* = \\underbrace{\\mathcal{Q}(\\underbrace{\\Delta_1 \\underbrace{\\Delta_7(\\underbrace{x-M A(x, 7)}_{\\text {detrend}})}_{\\text {de-seasonalize}})}_{\\text {de-correlate}}}_{\\text{normalize dist. by optimal transport}}$$\n",
        "\n",
        "where $MA(x, 7)$ is the (lagged) moving average, $\\Delta_k$ are the discrete differencing operators of order $k$ and $\\mathcal{Q}$ is quantile transform.\n",
        "We can see in the following cell how each of this transformations act on the time series, its distribution and on the auto correlation."
      ],
      "metadata": {
        "id": "t9UVx1lWRyx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import scipy.stats as stats\n",
        "from scipy.interpolate import PchipInterpolator\n",
        "\n",
        "class QTransform:\n",
        "\n",
        "  def __init__(self, n_points=100):\n",
        "    self.n_points = n_points\n",
        "    self.cdf = None\n",
        "    self.cdf_inv = None\n",
        "\n",
        "  def fit(self, df):\n",
        "    # define a grid on the domain of the data\n",
        "    alphas = np.quantile(df_ds, np.linspace(0.001, 1, self.n_points)).ravel()\n",
        "    # empirical CDF on the grid\n",
        "    cdf_points = np.array([(df<alpha).mean()[0] for alpha in alphas]) + np.linspace(0, 1e-10, self.n_points)\n",
        "    # ECDF function from the data\n",
        "    self.cdf = PchipInterpolator(alphas, cdf_points)\n",
        "    # inverse ECDF function from the data\n",
        "    self.cdf_inv = PchipInterpolator(cdf_points, alphas)\n",
        "    return self\n",
        "\n",
        "  def transform(self, df):\n",
        "    # x* = phi^{-1}(F(x)) = phi^{-1}(U) ~ Normal(0, 1)\n",
        "    return stats.norm.ppf(self.cdf(df.values))\n",
        "\n",
        "  def backtransform(self, df):\n",
        "    # F^{-1}(phi(x*)) = F^{-1}(U) ~ x\n",
        "    return self.cdf_inv(stats.norm.cdf(df))\n",
        "\n",
        "# detrended signal\n",
        "df = data-trend\n",
        "\n",
        "# detrended, de-seasonalized increments\n",
        "df_ds =(df-df.shift(7)).dropna()\n",
        "df_ds = (df_ds-df_ds.shift(1)).dropna()\n",
        "\n",
        "# normalized detrended, de-seasonalized increments\n",
        "qt_transform = QTransform().fit(df_ds)\n",
        "df_ds_qt = qt_transform.transform(df_ds)\n",
        "df_ds_qt = pd.DataFrame(df_ds_qt, index=df_ds.index)\n",
        "\n",
        "fig, ax = plt.subplots(4, 3, figsize=(15, 10))\n",
        "\n",
        "# distributions plots\n",
        "data.hist(bins=20, ax=ax[0, 0], density=True)\n",
        "df.hist(bins=20, ax=ax[1, 0], density=True)\n",
        "df_ds.hist(bins=20, ax=ax[2, 0], density=True)\n",
        "df_ds_qt.hist(bins=20, ax=ax[3, 0], density=True)\n",
        "\n",
        "# TS plots\n",
        "data.iloc[-300:].plot(ax=ax[0, 1])\n",
        "df.iloc[-300:].plot(ax=ax[1, 1])\n",
        "df_ds.iloc[-300:].plot(ax=ax[2, 1])\n",
        "df_ds_qt.iloc[-300:].plot(ax=ax[3, 1])\n",
        "\n",
        "# ACF plots\n",
        "_ = sm.graphics.tsa.plot_acf(data, lags=40, ax=ax[0, 2], title='Original data')\n",
        "_ = sm.graphics.tsa.plot_acf(df, lags=40, ax=ax[1, 2], title='detrended with lagged MAV')\n",
        "_ = sm.graphics.tsa.plot_acf(df_ds, lags=40, ax=ax[2, 2], title='detrended with lagged MAV, deseasonalized')\n",
        "_ = sm.graphics.tsa.plot_acf(df_ds_qt, lags=40, ax=ax[3, 2], title='detrended with lagged MAV, deseasonalized')\n",
        "\n",
        "# Add a normal Gaussian PDF on the QT-transformed signal\n",
        "x = np.linspace(-3,3, 100)\n",
        "ax[3, 0].plot(x, stats.norm.pdf(x, 0, 1))"
      ],
      "metadata": {
        "id": "pgHftCF1RyG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define a forecaster using this whitening process. In this specific case, this forecaster is even simpler than the vanilla linear model, since has just two parameters: the lag of the MA operator and the seasonality. In this case they are identical and set to 7.\n",
        "\n",
        "The mechanism is the following:\n",
        "* apply the above transformations on the training set, obtaining the whitened variable x* and store it\n",
        "* at prediction time, draw several random samples from x* and apply the inverse transformation\n",
        "\n",
        "This process generates several prediction scenarios, which chan be averaged to obtain a point forecast.\n",
        "\n",
        "### ❓ Complete the following forecaster\n",
        "Try to complete the fit method for the following forecaster\n"
      ],
      "metadata": {
        "id": "hB7mNznb36aU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StationarityForecaster:\n",
        "  def __init__(self, **kwargs):\n",
        "    self.qt_transform = None\n",
        "\n",
        "  def fit(self, df):\n",
        "    # detrend the signal with a MA\n",
        "    #df = ?                               # complete this line\n",
        "    # de-seasonalize\n",
        "    #df_ds =?                             # complete this line\n",
        "    # obtain first order differences\n",
        "    #df_ds_diff = ?                       # complete this line\n",
        "    # apply quantile transform\n",
        "    #df_ds_diff = ?                       # complete this line\n",
        "    # store scenarios of the same lenght of the prediction of the transformed variable x*\n",
        "    nmax = np.floor(df_ds_diff.shape[0]/7).astype(int)*7\n",
        "    self.noise_scenarios = df_ds_diff[-nmax:].reshape(7, -1)\n",
        "    return self\n",
        "\n",
        "  def predict(self, df, scenarios=False):\n",
        "    # sample stored x* scenarios\n",
        "    scens = self.noise_scenarios[:, np.random.choice(self.noise_scenarios.shape[1], 400)]\n",
        "    # backtransform the distribution\n",
        "    scens = self.qt_transform.backtransform(scens.T.ravel()).reshape(7, -1)\n",
        "    # integrate\n",
        "    scens = np.cumsum(scens, axis=0)\n",
        "    # add seasonality\n",
        "    scens = scens + df.values[-7:]\n",
        "    if scenarios:\n",
        "      return pd.DataFrame(scens, index=df.iloc[-7:].index + pd.to_timedelta('{}d'.format(7)))\n",
        "    return pd.DataFrame(np.mean(scens, axis=1), index=df.iloc[-7:].index + pd.to_timedelta('{}d'.format(7)),columns=['StationarityForecaster'])\n",
        "\n",
        "results = pd.concat({i*7:cross_validation(LinearForecaster, STLLinearForecaster, LinearDetrendedForecaster, StationarityForecaster,  embedding=7*i) for i in range(1, 5)}, axis=1)\n",
        "results.T.plot(figsize=(5, 4))\n",
        "plt.ylabel('nMAE');"
      ],
      "metadata": {
        "id": "_CnhsR23VdFB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PsBMBoV05LbX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 1, figsize=(15, 5))\n",
        "data.iloc[-100:].plot(ax=ax)\n",
        "StationarityForecaster().fit(data).predict(data, scenarios=True).plot(color='r', alpha=0.05, legend=False, ax=ax)"
      ],
      "metadata": {
        "id": "mqM-EvGIOIC7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
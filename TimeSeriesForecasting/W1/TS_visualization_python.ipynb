{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nepslor/teaching/blob/main/TimeSeriesForecasting/W1/TS_visualization_python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giQtorYsNtcZ"
      },
      "source": [
        "# Data analysis and modeling - Python\n",
        "In this lesson we will go through an example of exploratory analyisis and time series modeling with python. We will usa a dataset containing power measurements and meteorological forecasts relative to a set of 24 power meters located in Rolle (Switzerland).\n",
        "\n",
        "<img src=\"https://raw.githubusercontent.com/nepslor/teaching/main/TimeSeriesForecasting/figs/REeL_Demo_grid.png\" width=\"500\"/>\n",
        "\n",
        "The power measurements include mean active and reactive power, voltage magnitude and maximum total harmonic distortion (THD) for each phase, voltage frequency $\\omega$ and the average power over the three phases, $P_{mean}$.\n",
        "The meteorological forecasts include the temperature, global\n",
        "horizontal and normal irradiance (GHI and GNI, respectively),\n",
        "the relative humidity (RH) pressure and wind speed and\n",
        "direction (Ws and Wdir, respectively).\n",
        "<img src=\"https://raw.githubusercontent.com/nepslor/teaching/main/TimeSeriesForecasting/figs/REeL_data.png\" width=\"500\"/>\n",
        "\n",
        "We start importing and installing required packages, and reading the data [stored on Zenodo](https://zenodo.org/record/3463137#.Y_COj9LMKV4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zd60TjHuvxc"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install wget\n",
        "!pip install seaborn\n",
        "!pip install statsmodels==0.12.2\n",
        "!pip install tabulate\n",
        "import pandas as pd\n",
        "import wget\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3Liva4GlYqO"
      },
      "source": [
        "The dataframe contains a set of power series from different meters and the most updated forecasts of the global horizontal irradiance (GHI) and the temperature (T), povided by a numerical weather prediction service. Let's print some rows..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SoGFYOm_leIX"
      },
      "outputs": [],
      "source": [
        "data = pd.read_pickle(wget.download(\"https://zenodo.org/record/4549296/files/reduced_dataset.pk?download=1\"));\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSFXuHjfhYpz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# select just the electric meter time series\n",
        "plot_these = [n for n in data.columns if n not in [\"ghi_backwards\", \"temperature\"]]\n",
        "\n",
        "# plot the first 1000 points with transparency 0.3 and using a specific colormap\n",
        "data[plot_these].iloc[:1000,:].plot(alpha=0.3, cmap=plt.get_cmap('viridis'))\n",
        "\n",
        "# add some specs for the legend\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', ncol=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn9vPS1Gkohm"
      },
      "source": [
        "The data pd.DataFrame contains power signals from 24 secondary substations, and a list of their aggregations (S11,S12..) and the overall sum (all). We will focus on the prediction of the total aggregated power, so we discard the rest. For sake of simplicity, we will also downsample the dataframe to 1 hour sampling time. This is just a practical choice to avoid to use excessive computational power and ease the visualization of the different variables; it doesn't impact any following consideration.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "rkzZ6_Yfmdhx",
        "outputId": "dd736787-12dc-4f37-de5c-e7d529bce822"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                  all  \\\n",
              "2018-01-13 00:10:00+00:00  569.445444   \n",
              "2018-01-13 01:10:00+00:00  528.453278   \n",
              "2018-01-13 02:10:00+00:00  507.449722   \n",
              "2018-01-13 03:10:00+00:00  525.023444   \n",
              "2018-01-13 04:10:00+00:00  534.641833   \n",
              "\n",
              "                                                               ghi_backwards  \\\n",
              "2018-01-13 00:10:00+00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0361272897446...   \n",
              "2018-01-13 01:10:00+00:00  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0361272897446183, ...   \n",
              "2018-01-13 02:10:00+00:00  [0.0, 0.0, 0.0, 0.0, 1.0361272897446183, 38.77...   \n",
              "2018-01-13 03:10:00+00:00  [0.0, 0.0, 0.0, 1.0361272897446183, 38.7799425...   \n",
              "2018-01-13 04:10:00+00:00  [0.0, 0.0, 1.0361272897446183, 38.779942577378...   \n",
              "\n",
              "                                                                 temperature  \n",
              "2018-01-13 00:10:00+00:00  [3.6288461538461543, 3.589157030333501, 3.4878...  \n",
              "2018-01-13 01:10:00+00:00  [3.589157030333501, 3.4878365352875162, 3.4057...  \n",
              "2018-01-13 02:10:00+00:00  [3.4878365352875162, 3.405724059468352, 3.1049...  \n",
              "2018-01-13 03:10:00+00:00  [3.405724059468352, 3.1049134528586584, 2.6353...  \n",
              "2018-01-13 04:10:00+00:00  [3.1049134528586584, 2.635389610389611, 2.4121...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c2926c2b-3673-458d-8416-55a59546bfbd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>all</th>\n",
              "      <th>ghi_backwards</th>\n",
              "      <th>temperature</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2018-01-13 00:10:00+00:00</th>\n",
              "      <td>569.445444</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0361272897446...</td>\n",
              "      <td>[3.6288461538461543, 3.589157030333501, 3.4878...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-13 01:10:00+00:00</th>\n",
              "      <td>528.453278</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0361272897446183, ...</td>\n",
              "      <td>[3.589157030333501, 3.4878365352875162, 3.4057...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-13 02:10:00+00:00</th>\n",
              "      <td>507.449722</td>\n",
              "      <td>[0.0, 0.0, 0.0, 0.0, 1.0361272897446183, 38.77...</td>\n",
              "      <td>[3.4878365352875162, 3.405724059468352, 3.1049...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-13 03:10:00+00:00</th>\n",
              "      <td>525.023444</td>\n",
              "      <td>[0.0, 0.0, 0.0, 1.0361272897446183, 38.7799425...</td>\n",
              "      <td>[3.405724059468352, 3.1049134528586584, 2.6353...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2018-01-13 04:10:00+00:00</th>\n",
              "      <td>534.641833</td>\n",
              "      <td>[0.0, 0.0, 1.0361272897446183, 38.779942577378...</td>\n",
              "      <td>[3.1049134528586584, 2.635389610389611, 2.4121...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c2926c2b-3673-458d-8416-55a59546bfbd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c2926c2b-3673-458d-8416-55a59546bfbd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c2926c2b-3673-458d-8416-55a59546bfbd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "samples_per_day = 24\n",
        "\n",
        "# create 1-hour means of the original time series\n",
        "p_all = data['all'].resample('1h', origin='start').mean()\n",
        "\n",
        "# since NWP forecasts are provided as vectors we won't mediate them but take one row in 6 (= instantaneous hourly prediction)\n",
        "data = pd.concat([p_all,data['ghi_backwards'].iloc[::6], data['temperature'].iloc[::6]], axis=1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ❓ Auto Correlation Function\n",
        "The Auto Correlation Function (ACF), $\\rho_k$, returns the normalized correlation of a signal with itself at lag $k$.\n",
        "\n",
        "Try to plot the autocorrelation function for different lags $k$ for the 'all' signal. You can use the `.autocorr` pandas function."
      ],
      "metadata": {
        "id": "3CQwSOwKqpsl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_G288Siop1dE"
      },
      "outputs": [],
      "source": [
        "# Plotting ACF for the four signals\n",
        "\n",
        "# Plotting the associated time series\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akgqC50gy_aQ"
      },
      "source": [
        "Strong seasonalities can be spotted at 24 hours intervals, with a second local maximum after 7 days (the second dashed vertical line), indicating a strong weekly seasonality. As a comparison, the orange and the green lines represent the autocorrelations of white noise (iid samples from a noraml distribution) and of brownian motion.\n",
        "\n",
        "\n",
        "## ❓ Embeddings\n",
        "We can now try to use the two local maxima as embedding for the time series, and try to see if the signal can be compressed. Try to obtain two matrices, d_mat and weeks_mat, using 24 and 24*7 steps as embedding dimension (corresponding to the first two maxima of the auto correlation function) and plot the resulting matrices as a picture.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8U5S9czqPXmG"
      },
      "outputs": [],
      "source": [
        "\n",
        "l = len(data['all'])\n",
        "n_max = int(l/(samples_per_day*7))*samples_per_day*7\n",
        "# d_mat = ?       # complete this line\n",
        "# weeks_mat = ?   # complete this line\n",
        "\n",
        "plt.matshow(d_mat, aspect='auto')\n",
        "plt.xlabel('days')\n",
        "plt.ylabel('time from midnight [1 h]')\n",
        "plt.colorbar(label='total power [kW]');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs1l1A0ibx_E"
      },
      "source": [
        "The above picture can be interpreted as following: the columns of the above matrix represent days, while its rows correspond to different times of a given day. We can observe how daily peaks (lighter pixels) usually occurs at the same time of the day. At the same time we observe the daylight saving shift, meaning that the timestamp of the data is in UTC. This means that if we want to use the hour of the day as an explanatory variable we should transform the timestamp in localtime first. Now let's try to plot the same data as time series, using both one day and one week as embedding, to see if we can gain more insight."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPTluILGV8P9"
      },
      "outputs": [],
      "source": [
        "colors = plt.get_cmap('plasma',7)\n",
        "fig, ax = plt.subplots(1,2, figsize=(15,5))\n",
        "plt.subplots_adjust(wspace=0)\n",
        "[ax[0].plot(d_mat[:, i::7], c=colors(1 if i>1 else 3), alpha=0.1) for i in range(7)];\n",
        "ax[0].set_xlim(0,samples_per_day-1)\n",
        "ax[0].set_xlabel('day time [10 mins]')\n",
        "ax[0].set_ylabel('P [kW]')\n",
        "ax[0].set_title('daily time series')\n",
        "\n",
        "\n",
        "ax[1].plot(weeks_mat, alpha=0.1, color=colors(0));\n",
        "[ax[1].axvspan(samples_per_day*i, samples_per_day*(i+1), alpha=0.1, color=colors(1 if i>1 else 3)) for i in range(7)];\n",
        "ax[1].set_xlim(0,samples_per_day*7-1)\n",
        "ax[1].set_yticks([]);\n",
        "ax[1].set_xlabel('week time [10 mins]');\n",
        "ax[1].set_title('weekly time series');\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1rMOeDSeBih"
      },
      "source": [
        "In the above picture the data embedding dimension is 24 and 168, for the right and left panels, respectively. We can see how daily data is highly self-similar, but two clusters can be distinguished: weekdays and weekends. The same can be observed looking at the 7 days embedding (left), where the red vertical bands corresponds to weekends. This kind of visualization guides us in the choice of the forecasting model: we can already see how a simple AR model will probably perform poorly if we do not include 168 autoregressive steps. More on this later on. Let's now visualize interactions between the variable, its lag at -1 day, and the meteorological variables in the dataset. We resample the data to 1 hour sampling time to avoid eccessive computational time in the visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxfwXVtMgfzQ"
      },
      "outputs": [],
      "source": [
        "import seaborn as sb\n",
        "all_1d_delay = np.roll(data[['all']].values, shift=samples_per_day)[samples_per_day:]                              # np.roll shifts the array by \"shift\" steps\n",
        "ghi = np.vstack(data['ghi_backwards'])[samples_per_day:,[0]]\n",
        "temperature = np.vstack(data['temperature'])[samples_per_day:,[0]]\n",
        "plot_data = pd.DataFrame(np.hstack([data[['all']].values[samples_per_day:],all_1d_delay,\n",
        "                                    ghi, temperature]), columns\n",
        "                         =['all', 'all d-1','ghi', 'T'], index=data.index[samples_per_day:])\n",
        "sb.pairplot(plot_data,plot_kws={\"s\": 3, \"alpha\":0.2})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faR81kSNt84B"
      },
      "source": [
        "We can see how the power at current time is highly correlated with its daily lag, as we expected to see from the ACF plot. We can observe also a slightly negative correlation with the temperature predicted by the NWP service for the next hour. This can indicate the presence of electric-based heating, like heat pumps. On the other hand, we cannot spot an evident correlation with the solar irradiation, which means no relevant amount of PVs power plants are installed in this grid.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#❓Some exploratory analysis\n",
        "* Among the bottom time series, find the most similar and most dissimilar couples\n",
        "* Look at the most dissimilar couple. Try to scatter them against the values of the predicted GHI\n",
        "* Can you spot other series for which the GHI has a similar effect?\n"
      ],
      "metadata": {
        "id": "VaW_-Nh_b5eJ"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "faR81kSNt84B"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}